【 題目四 】

試想已有一組 ELK/EFK 日誌服務集群,而今日有一新服務上線並且串接日誌紀錄,讓開發者
能夠透過 Kibana 進行線上錯誤排查,你/妳會如何將日誌檔內容串接至 ELK/EFK 系統?考
量的細節是什麼?

【 題目四解答 】

將新服務的日誌串接至 ELK/EFK 系統需要考慮以下幾個面向：

1. 日誌格式標準化
   ```json
   {
     "timestamp": "2025-01-20T11:11:17+08:00",
     "level": "ERROR",
     "service": "user-service",
     "trace_id": "abc123",
     "message": "Failed to process request",
     "metadata": {
       "request_id": "req123",
       "user_id": "user456",
       "endpoint": "/api/v1/users"
     }
   }
   ```
   - 確保關鍵字段統一：
     * timestamp 格式（ISO 8601）
     * log level 標準化
     * 必要的 metadata（service name, trace ID）
   - 使用結構化日誌格式（JSON）

2. 日誌收集配置
   a. Filebeat 配置示例：
   ```yaml
   filebeat.inputs:
   - type: log
     enabled: true
     paths:
       - /var/log/application/*.log
     json.keys_under_root: true
     json.add_error_key: true
     processors:
       - add_host_metadata: ~
       - add_cloud_metadata: ~
       - add_kubernetes_metadata:
           host: ${NODE_NAME}
   
   output.elasticsearch:
     hosts: ["elasticsearch:9200"]
     index: "application-%{[agent.version]}-%{+yyyy.MM.dd}"
   
   setup.template.name: "application"
   setup.template.pattern: "application-*"
   setup.ilm.enabled: true
   ```

   b. Fluentd 配置示例：
   ```xml
   <source>
     @type tail
     path /var/log/application/*.log
     pos_file /var/log/td-agent/application.log.pos
     tag application.*
     <parse>
       @type json
       time_key timestamp
       time_format %Y-%m-%dT%H:%M:%S%z
     </parse>
   </source>

   <filter application.**>
     @type record_transformer
     <record>
       hostname ${hostname}
       environment ${ENV:-production}
     </record>
   </filter>

   <match application.**>
     @type elasticsearch
     host elasticsearch
     port 9200
     logstash_format true
     logstash_prefix application
     flush_interval 5s
   </match>
   ```

3. Elasticsearch 索引配置
   ```json
   {
     "template": "application-*",
     "settings": {
       "number_of_shards": 3,
       "number_of_replicas": 1,
       "index.lifecycle.name": "application-policy",
       "index.lifecycle.rollover_alias": "application"
     },
     "mappings": {
       "properties": {
         "timestamp": {
           "type": "date"
         },
         "level": {
           "type": "keyword"
         },
         "service": {
           "type": "keyword"
         },
         "trace_id": {
           "type": "keyword"
         },
         "message": {
           "type": "text"
         }
       }
     }
   }
   ```

4. Kibana 可視化配置
   - 設置索引模式：
     * Pattern: `application-*`
     * Time field: `timestamp`
   - 建立常用搜索：
     * 錯誤日誌查詢
     * 特定服務日誌
     * 追蹤特定請求

5. 性能考量
   a. 日誌收集
   - 使用批量收集減少 I/O
   - 設置合適的 buffer 大小
   - 配置適當的輪轉策略
   ```yaml
   # Filebeat performance tuning
   filebeat.inputs:
     - bulk_max_size: 2048
       harvester_buffer_size: 16384
   
   queue.mem:
     events: 4096
     flush.min_events: 512
     flush.timeout: 5s
   ```

   b. Elasticsearch 優化
   - 設置合適的分片數
   - 配置 Index Lifecycle Management
   ```json
   {
     "policy": {
       "phases": {
         "hot": {
           "min_age": "0ms",
           "actions": {
             "rollover": {
               "max_size": "50GB",
               "max_age": "7d"
             }
           }
         },
         "warm": {
           "min_age": "7d",
           "actions": {
             "shrink": {
               "number_of_shards": 1
             }
           }
         },
         "delete": {
           "min_age": "30d",
           "actions": {
             "delete": {}
           }
         }
       }
     }
   }
   ```

6. 監控和告警
   - 設置 Elasticsearch 集群監控
   - 配置日誌收集監控
   - 設置錯誤告警
   ```json
   {
     "trigger": {
       "schedule": {
         "interval": "5m"
       }
     },
     "input": {
       "search": {
         "request": {
           "indices": ["application-*"],
           "body": {
             "query": {
               "bool": {
                 "must": [
                   { "match": { "level": "ERROR" } }
                 ],
                 "filter": {
                   "range": {
                     "timestamp": {
                       "gte": "now-5m"
                     }
                   }
                 }
               }
             }
           }
         }
       }
     },
     "condition": {
       "compare": {
         "ctx.payload.hits.total": {
           "gt": 100
         }
       }
     },
     "actions": {
       "notify": {
         "webhook": {
           "scheme": "https",
           "host": "alerts.example.com",
           "port": 443,
           "method": "post",
           "path": "/alert"
         }
       }
     }
   }
   ```

7. 安全性考量
   - 配置 TLS/SSL 加密
   - 實施適當的訪問控制
   - 敏感資訊脫敏
   ```yaml
   # Filebeat security settings
   output.elasticsearch:
     protocol: "https"
     ssl.certificate_authorities: ["ca.pem"]
     ssl.certificate: "client.pem"
     ssl.key: "client.key"
   
   # Field masking processor
   processors:
     - drop_fields:
         fields: ["password", "credit_card"]
     - rename:
         fields:
           - from: "user_email"
             to: "user_id"
   ```

最佳實踐建議：
1. 實施分層日誌策略：
   - DEBUG/INFO → 較短保留期
   - WARN/ERROR → 較長保留期
2. 建立日誌規範文檔
3. 定期審查和優化配置
4. 實施日誌輪轉和清理策略
5. 建立備份和恢復機制